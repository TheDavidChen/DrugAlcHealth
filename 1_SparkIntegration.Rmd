---
title: "1_SparkIntegration"
author: "David Chen"
date: "April 26, 2019"
output: html_document
---


```{r message = FALSE, include = FALSE}

rm(list = ls())

# libraries
library(data.table)
library(tidyverse)
library(lubridate)
#library(sparklyr)
library(parallel)

# load data
educ_raw <-
  fread("Data/Education.csv")
healthexp_raw <-
  fread("Data/HealthExpend.csv")
pop_raw <-
  fread("Data/PopulationEstimates.csv")
poverty_raw <-
  fread("Data/PovertyEstimates.csv")
unemp_raw <-
  fread("Data/Unemployment.csv")
drugmort_raw <-
  fread("Data/Compressed Mortality, 1999-2016.txt")

# define functions

```

```{r}
# spark_install()
sc <- spark_connect(master = 'local')
```

```{r}
my_cores <- detectCores()
my_cores

```

```{r}

unlist(mclapply(HealthData$State, FUN = identify_region, mc.cores = 1))



HealthData_region <- 
  HealthData %>%
  
  # This line identifies the region and creates the variable
  # Non-elegant solution but shows use of mclappy
  ### Note: Windows users are only able to apply one core so it is done here
  mutate(region = unlist(mclapply(HealthData$State, 
                                  FUN = identify_region, mc.cores = 1))) %>%
  
  # Create a copy of region to unnest and spread
  mutate(region_copy = region) %>%
  
  # The following code creates dummy variables for region
  unnest(region_copy) %>% 
  mutate(new = 1) %>% 
  spread(region_copy, new, fill = 0) 

```

```{r}


```

```{r}


```

```{r}


```

