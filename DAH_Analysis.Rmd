---
title: "Drug and Alcohol Health Analysis"
author: "Deric Liang and David Chen"
date: "04/30/2019"
output: html_document
---

In this project, we use classical regression models and supervised learning methods to link health expenditure, among other variables, by state and state census data to drug and alcohol overdose deaths. In exploring this relationship, we seek to understand whether the amount of funds invested in the health of citizens plays a role in preventing deaths from drugs and make recommendations on whether states which see more drug deaths should consider increasing health expenditures. Data sources can be found in the README.md file.

```{r message = FALSE, include = FALSE}
# Clean up R environment
rm(list = ls())

# libraries
library(data.table)
library(tidyverse)
library(lubridate)
library(leaps)
library(rpart)
library(partykit)
library(caret)
library(randomForest)

# load data
educ_raw <-
  fread("Data/Education.csv")
healthexp_raw <-
  fread("Data/HealthExpend.csv", header = TRUE)
# pop_raw <-
#   fread("Data/PopulationEstimates.csv")
### population counts included in drug mortality data
poverty_raw <-
  fread("Data/PovertyEstimates.csv")
unemp_raw <-
  fread("Data/Unemployment.csv")
drugmort_raw <-
  fread("Data/Compressed Mortality, 1999-2016.txt")

unint_death <- 
  fread('Data/X4045_Mortality.txt')
int_death <-
  fread('Data/X6065_Mortality.txt')

# define functions

identify_region <- function(state) {
  # Purpose: This functions identifies the region of a state
  # Inputs:
  ### state: United States state in a character format
  # Output: Which region of the United States the state applies to. If none, NA.
  
  Northeast <- c('Maine', 'New Hampshire', 'Vermont', 'Massachusetts', 
               'Rhode Island', 'Connecticut', 'New York', 'New Jersey',
               'Pennsylvania')

  Midwest <- c('Ohio', 'Michigan', 'Indiana', 'Wisconsin', 'Illinois', 
               'Minnesota', 'Iowa', 'Missouri', 'North Dakota', 
               'South Dakota', 'Nebraska', 'Kansas')
  
  South <- c('Delaware', 'Maryland', 'Virginia', 'West Virginia', 'Kentucky', 
             'North Carolina', 'South Carolina', 'Tennessee', 'Georgia', 
             'Florida', 'Alabama', 'Mississippi', 'Arkansas', 'Louisiana', 
             'Texas', 'Oklahoma')
  
  West <- c('Montana', 'Idaho', 'Wyoming', 'Colorado', 'New Mexico', 
            'Arizona', 'Utah', 'Nevada', 'California', 'Oregon', 
            'Washington', 'Alaska', 'Hawaii')
  
  if (state %in% Northeast) {
    return('Northeast')
  }
  else if (state %in% Midwest) {
    return('Midwest')
  }
  else if (state %in% South) {
    return('South') 
  }
  else if (state %in% West) {
    return('West')
  }
  else {
    return(NA)
  }
}

```

## Data Wrangling
```{r}
# Drug Mortality Data
### Remove unnecessary columns and `Total` row
drugmort <-
  drugmort_raw %>%
  na.omit() %>%
  select(-Notes, -`State Code`) %>%
  mutate(Deaths = as.numeric(Deaths)) %>%
  rename(DrugDeaths = Deaths,
         DrugMortalityRate = `Crude Rate`)

# Education Level Data
### Clean headers, select for state data, select relevant columns
educ <-
  educ_raw %>%
  distinct(State, .keep_all = TRUE) %>%
  filter(`FIPS Code` != is.na(`FIPS Code`),
         State != "PR") %>%
  select(`Area name`, `Percent of adults with a bachelor's degree or higher, 2013-17`,
         `Percent of adults completing some college or associate's degree, 2013-17`,
         `Percent of adults with a high school diploma only, 2013-17`,
         `Percent of adults with less than a high school diploma, 2013-17`) %>%
  rename(State = `Area name`,
         PercentBachelor = `Percent of adults with a bachelor's degree or higher, 2013-17`,
         PercentAssoc = `Percent of adults completing some college or associate's degree, 2013-17`,
         PercentHS = `Percent of adults with a high school diploma only, 2013-17`,
         PercentLessHS = `Percent of adults with less than a high school diploma, 2013-17`)

# Health Expenditure Data
### Remove non-state rows, extraneous column
healthexp <-
  healthexp_raw[1:51] %>%
  rename(HealthExpenditure = `2016`, State = STATE) %>%
  mutate(HealthExpenditure = parse_number(HealthExpenditure)) %>%
  select(State, HealthExpenditure)

# Poverty Data
### Clean headers, select for state data, select relevant columns
poverty_raw$State[poverty_raw$State == "Wi"] <- "WI"
poverty <-
  poverty_raw %>%
  distinct(State, .keep_all = TRUE) %>%
  filter(FIPStxt != is.na(FIPStxt)) %>%
  select(Area_Name, POVALL_2017, PCTPOVALL_2017, POV017_2017, PCTPOV017_2017) %>%
  rename(State = Area_Name,
         PovertyCountAll = POVALL_2017,
         PovertyPctAll = PCTPOVALL_2017,
         PovertyCount0_17 = POV017_2017,
         PovertyPctAll0_17 = PCTPOV017_2017) %>%
  mutate(PovertyCountAll = parse_number(PovertyCountAll),
         PovertyCount0_17 = parse_number(PovertyCount0_17))

# Unemployment Data
### Clean headers, select for state data, select relevant columns
unemp_raw$State[unemp_raw$State == "Co"] <- "CO"
unemployment <-
  unemp_raw %>%
  distinct(State, .keep_all = TRUE) %>%
  filter(FIPStxt != is.na(FIPStxt),
         State != "PR") %>%
  select(Area_name, Civilian_labor_force_2016, Unemployed_2016, Unemployment_rate_2016) %>%
  rename(State = Area_name,
         LaborForce = Civilian_labor_force_2016,
         Unemployed = Unemployed_2016,
         UnemploymentRate = Unemployment_rate_2016) %>%
  mutate(LaborForce = parse_number(LaborForce),
         Unemployed = parse_number(Unemployed))

```

```{r}
# Adding in intentional and unintentional deaths as separate variables
intdeath <-
  int_death %>%
  filter(State != "District of Columbia") %>%
  select(-Notes, -`State Code`) %>%
  mutate(Deaths = as.numeric(Deaths)) %>%
  rename(int_DrugDeaths = Deaths,
         int_DrugMortalityRate = `Crude Rate`) %>%
  # Some values are considered unreliable but we will continue to use them for this analysis
  mutate(int_DrugMortalityRate = parse_number(int_DrugMortalityRate))

unintdeath <-
  unint_death %>%
  filter(State != "District of Columbia") %>%
  select(-Notes, -`State Code`, -`Population`) %>%
  mutate(Deaths = as.numeric(Deaths)) %>%
  rename(unint_DrugDeaths = Deaths,
         unint_DrugMortalityRate = `Crude Rate`) 


combined_deaths <- 
  left_join(intdeath, unintdeath, by = 'State')


HealthData <-
  left_join(combined_deaths, drugmort, by = c("State", 'Population')) %>%
  left_join(healthexp, by = "State") %>%
  left_join(educ, by = 'State') %>%
  left_join(poverty, by = 'State') %>%
  left_join(unemployment, by = 'State') %>%
  filter(State != "District of Columbia")
```

### Data Wrangling - Regions according to the US Census Bureau:  

Sourced from : https://www.businessinsider.com/united-states-regions-new-england-midwest-south-2018-4    

1. "The Northeast includes Maine, New Hampshire, Vermont, Massachusetts, Rhode Island, Connecticut, New York, New Jersey, and Pennsylvania."  

2. "[The Midwest] consists of Ohio, Michigan, Indiana, Wisconsin, Illinois, Minnesota, Iowa, Missouri, North Dakota, South Dakota, Nebraska, and Kansas."  

3. "...the South consists of Delaware, Maryland, Virginia, West Virginia, Kentucky, North Carolina, South Carolina, Tennessee, Georgia, Florida, Alabama, Mississippi, Arkansas, Louisiana, Texas, and Oklahoma."   

4. "The West consists of Montana, Idaho, Wyoming, Colorado, New Mexico, Arizona, Utah, Nevada, California, Oregon, Washington, Alaska, and Hawaii."  

```{r}
# Attaching region to dataset

HealthData_region <- 
  HealthData %>%
  
  # This line identifies the region and creates the variable
  mutate(region = sapply(HealthData$State, FUN = identify_region)) %>%
  
  # Create a copy of region to unnest and spread
  mutate(region_copy = region) %>%
  
  # The following code creates dummy variables for region
  unnest(region_copy) %>% 
  mutate(new = 1) %>% 
  spread(region_copy, new, fill = 0) 

```


Now that we've finally finished consolidating all the datasets -- it's time to start doing some basic EDA! First, we want to examine the relationship between intentional and unintentional drug mortality rates. As expected, for the raw counts there appears to be a fairly strong relationship, with unintentional deaths far higher than intentional. However, much to our surprise, there doesn't appear to be a strong relationship between the Crude rates (per 100,000). 
```{r}
#EDA 

ggplot(HealthData_region, aes(x = unint_DrugDeaths, 
                              y = int_DrugDeaths, color = region)) +
  geom_point() +
  labs(x = 'Unintentional Drug Self-Poisoning Deaths', 
       y = 'Intentional Drug Self-Poisoning Deaths', 
       title = 'Unintentional vs Intentional Drug Self-Poisoning Deaths (per 100,000)')

ggplot(HealthData_region, aes(x = unint_DrugMortalityRate, 
                              y = int_DrugMortalityRate, color = region)) +
  geom_point() + 
  labs(x = 'Unintentional Drug Mortality Rate', 
       y = 'Intentional Drug Mortality Rate', 
       title = 'Unintentional vs Intentional Drug Mortality Rates (per 100,000)') +
  xlim(0, 50) + 
  ylim(0, 4)
```

We want to look further to see if there is any similarities between the regions. By creating a faceted graph, we can directly compare the regions. We can immediately see that the Western region appears to be unique with intentional drug mortality rates peaking with low unintentional drug mortality rates. The remaining three regions appear to be similar, although there definitely appears to be some differentiation. 
```{r}

temp <- HealthData_region
temp$Region <- factor(temp$region, levels = c('Northeast', 'Midwest', 'West', 'South'))

ggplot(temp, aes(x = unint_DrugMortalityRate, 
                              y = int_DrugMortalityRate, color = Region)) +
  geom_point() + 
  labs(x = 'Unintentional Drug Mortality Rate', 
       y = 'Intentional Drug Mortality Rate', 
       title = 'Unintentional vs Intentional Drug Mortality Rates (per 100,000)') +
  facet_wrap(~Region, nrow = 1)

```

Now that we've processed the individual rates, perhaps it's time to look more specifically at the states. By ordering the combined rates (intentional + unintentional) we can see which states are more affected than others. For example, we can clearly see that West Virginia is an outlier. The regions appear to be fairly well mixed as well. 
```{r}

testing <- HealthData_region$State
p <-
  ggplot(HealthData_region, aes(x = reorder(State, -DrugMortalityRate),
                                y = DrugMortalityRate)) +
  geom_col(data = HealthData_region, aes(fill = region)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(y = 'Combined Drug Mortality Rate per 100,000', 
       x = 'State', title = 'Combined Drug Mortality Rate per 100,000 by State') 

p +
  geom_point(data = unintdeath, aes(x = State, y = unint_DrugMortalityRate)) +
  geom_point(data = intdeath, aes(x = State, y = int_DrugMortalityRate)) 
```

Next we want to examine the influence of per capita Health Expenditures on the overall Drug Mortality rate. By subsetting into regions, we can immediately see that there is no immediate linear trend. We will need to investigate further to see what factors influence the various rates. 
```{r}
ggplot(HealthData_region, aes(x = HealthExpenditure, y = DrugMortalityRate,  color = region)) +
  geom_point() +
  xlim(0, 650) +
  ylim(0, 50) +
  facet_wrap(~region, nrow = 1) +
  labs(x = 'Health Expenditure per Capita ($)', 
       y = 'Drug Mortality Rate (per 100,000)', 
       title = 'Drug Mortality Rate vs Health Expenditures by Region')
```

## Regression Models/Supervised Learning

We define the formula that indicates the relationship we want to explore in this analysis. This indicates that we seek to explore how health expenditure, education level, poverty level, and unemployment rate affect drug mortality rate.

```{r}
form <- 
  DrugMortalityRate ~ HealthExpenditure + PercentBachelor + PovertyPctAll + UnemploymentRate
```

### Null Model

The first task is to set up a null model, in order to have a baselline to compare the rest of our models to. We certainly do not want any of our models to perform worse than the null model.

```{r}
null_mod <-
  lm(DrugMortalityRate ~ 1, data = HealthData_region)
summary(null_mod)
nullrsq <-
  1 - sum((null_mod$residuals)^2) / sum((HealthData_region$DrugMortalityRate - mean(HealthData_region$DrugMortalityRate))^2)
nullrsq
```

The mean drug mortality rate for the data is 20.124, with an R-squared of $1.11 * 10^{-16}$. This indicates that the drug mortality rate is non-constant across states, and there are likely other factors influencing it.

### Regression

The common and most interpretable method used to explore relationships between variables is regression techniques, so we perform this before building other models. To begin, we fit the full linear regression model with all the regressors previously indicated.

```{r}
fullhealth_lm <-
  lm(form, data = HealthData_region)
summary(fullhealth_lm)
plot(fullhealth_lm)
```

This fitted model is not good; none of the regressors are significant. Therefore, we would like to create subsets to compare the BIC of different models that can be built with these regressors. The lowest BIC indicates the best fit.

```{r}
subsets <-
  regsubsets(form, data = HealthData_region, nbest = 5)
plot(subsets)
```

The model with just the unemployment rate regressor is the best. Therefore, we want to fit a regression model with only that regressor. Since this is a simple linear regression problem, it is useful to first visualize the relationship between drug mortality rate and unemployment rate.

```{r}
HealthData_region %>%
  ggplot(aes(x = UnemploymentRate, y = DrugMortalityRate)) +
  geom_point(aes(color = region)) +
  stat_smooth(color = "grey50", method = lm, se = 0) +
  xlab("Unemployment Rate") +
  ylab("Drug Mortality Rate") +
  labs(title = "Drug Mortality Rate vs. Unemployment Rate")
```

Visually, the data seems to follow a fairly strong positive linear trend. We are now interested in seeing whether the relationship is statistically significant.

```{r}
red_lm <-
  lm(DrugMortalityRate ~ UnemploymentRate, data = HealthData_region)
summary(red_lm)
plot(red_lm)
```

Our regression modeling shows us that only the Unemployment Rate has a significant effect on the Drug Mortality Rate. Checking diagnostics plots, we are fine to assume linearity, independence, normality, and equivariance, such that the given regression coefficients and fit are not misleading.

### Supervised Learning

We want to explore other modeling methods which could help us predict Drug Mortality Rate, beyond classical regression models.

*Regression Tree*

We first fit a regression tree, which will help us understand how the drug mortality rate will change based off of different grouped values of our predictors.

```{r}
regtree <-
  rpart(form, data = HealthData_region)
plot(as.party(regtree))
```

The regression tree shows that the education level (the percent of people who have a Bachelor's degree) is also significant in predicting Drug Mortality Rate, in addition to Unemployment Rate. An unemployment rate greater than or equal to 4.45% shows higher drug mortality, and within that group, states with less than 27.65% of people having a Bachelors shows higher drug mortality than states with more than 27.65% of people having a Bachelors. For states with an unemployment rate of less than 4.45%, states with more than 32.4% of people having a Bachelors has a higher drug mortality than states with less than 32.4% of people having a Bachelors. This generally shows that unemployment rate is more important than the education level in predicting drug mortality rate.

```{r}
# define training control
train_control <- 
  trainControl(method = "cv", number = 10)
# train the model
regtreecv <- 
  form %>%
  train(data = na.omit(HealthData_region), trControl = train_control, method = "rpart")
# summarize results
regtreecv
```

The Regression Tree gives an R-squared of 0.3113, much better than the previous models.

*Random Forest*

Next, we would like to fit a random forest model. This will give us an idea of the most to least important predictors in predicting drug mortality rate.

```{r}
# train the model
forestcv <- 
  form %>%
  train(data = na.omit(HealthData_region), trControl = train_control, method = "rf")
# summarize results
forestcv
```

```{r}
trainforest <-
  randomForest(form, data = HealthData_region, ntree = 200, 
               mtry = 2, na.action = na.omit)
importance(trainforest) %>%
  as.data.frame() %>%
  rownames_to_column() %>%
  arrange(desc(IncNodePurity))
```

The Random Forest (with mtry = 2) gives an R-squared of 0.1924, worse than the regression tree but better than the other models. This model states that the percent of people with a Bachelors is the most important predictor of drug mortality rate, followed by unemployment rate, then percent of people in poverty, then health expenditure. This is consistent with what we have found in previous models, and is important to see as the biggest question in exploring this data was to see whether health expenditure affected drug mortality rates, and here we see it is not as important as other factors.

### Supervised Learning Summary

Generally, we learned that the unemployment rate and education level (the percent of people with a Bachelors) are the biggest predictors in drug mortality rate, consistent across several models. The percent of people in poverty and health expenditure are not as significant in predicting drug mortality rate.

## Unsupervised Learning

First we wanted to conduct a PCA to see how much the dataset could be reduced. We first removed categorical variables and dummy variables (the region variables), as well as variables that could be calculated through the other variables (Most notably DrugDeaths and DrugMortalityRate). Then, as Population and crude rates are included, direct values such as number of Unemployed are removed. 
```{r}
HealthData_pca <- 
  HealthData_region %>%
  select(-c('State', 'region', 'DrugDeaths', 'DrugMortalityRate', 'Midwest', 'Northeast',
            'South', 'West', 'PercentAssoc', 'Unemployed', 'PovertyCountAll')) %>%
  na.omit() %>%
  prcomp(scale = TRUE)  
```

We then examine the two top PCA to see how they are composed. 
```{r}
(-1) * HealthData_pca$rotation[, 1:2] %>% round(2)
```

Plotting the states and regions by the two top PCA components we can see that there appears to be a central cluster of most states before it forms "wings" on both ends. We can also immediately see that California and West Virginia seem to be two unique states that can be examined further. 
```{r}
# Louisiana is missing values so they are omitted. 
names <- na.omit(HealthData_region)
Region <- names$region

HealthData_pca$x %>%
  as.data.frame() %>%  
  rownames_to_column() %>%
  ggplot(aes(x = PC1, y = PC2)) + 
  geom_text(aes(label = names$State), size = 3) + 
  xlab("Best Vector from PCA (approx. Intentional Drug Self-Poisoning Rate") + 
  ylab("2nd Best Vector from PCA (approx. Education)") + 
  ggtitle("Two-dimensional representation of Drug Mortality by State")

HealthData_pca$x %>%
  as.data.frame() %>%  
  ggplot(aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = Region), size = 3) + 
  xlab("Best Vector from PCA (approx. Intentional Drug Self-Poisoning Rate") + 
  ylab("2nd Best Vector from PCA (approx. Education)") + 
  ggtitle("Two-dimensional representation of Drug Mortality by Region")
```

For the sake of understanding our PCA analysis further we create the scree plot and cumulative PVE plot. Here we can see that the first two PCA components immediately account for a majority of the variation in the data, making our previous analysis a fairly strong representation of the data. 
```{r}

HealthData_pve <- 
  data.frame(sd = HealthData_pca$sdev) %>%
  rownames_to_column() %>%
  mutate(rowname = parse_number(rowname), 
         totalVar = sum(HealthData_pca$sdev^2), 
         pve = 100 * sd^2 / totalVar, 
         cusum = cumsum(pve))

# scree plot
HealthData_pve %>%
  ggplot(aes(x = rowname, y = pve)) + 
  geom_line(type = 3) + 
  xlab("Principal Component") + 
  ylab("Proportion of Variance Explained") + 
  ggtitle("Scree Plot of Principal Components for Health Data") 

  
# cumulative PVE plot
HealthData_pve %>%
  ggplot(aes(x = rowname, y = cusum)) + 
  geom_line(type = 3) + 
  xlab("Principal Component") + 
  ylab("Proportion of Variance Explained") + 
  ggtitle("Cumulative Proportion of Variance Explained for Health Data") 

```

Having conducted the PCA analysis, we now want to move on to examine the different clustering techniques and see if the Census Bureau's designation of regions is reflected in our data. If we recall from the previous data wrangling, the US Census Bureau classifies US states into four regions: South, Northeast, Midwest, and West. 
```{r}
HD_std <- 
  HealthData_region %>%
  select(c(int_DrugMortalityRate, unint_DrugMortalityRate, HealthExpenditure)) %>%
  na.omit() %>%
  scale() %>%
  as.data.frame()
```

By creating a Dendogram we can see the varying amounts of differentiation each state has from the next. We can immediately see 2-3 distinct groups, eliciting us to investigate further into the attributes of each state. 
```{r}

HD_dist <- dist(HD_std)

HD_dendo <-
  HD_dist %>%
  hclust(method = "complete")

HD_dendo %>%
  plot(cex = 0.9, labels = HealthData_region$State, lwd = 2,
       main = "Health Data Dendogram with Complete Linkage")

```

We can also draw a line to mark the cutoff for the first 4 clusters, following our attempts to identify representation of the Census designated regions. 
```{r}
HD_dendo %>%
  plot(labels = HealthData_region$State, lwd = 2,
       main = "Health Data Dendogram with Complete Linkage (4 clusters)") %>%
  abline(h = 4.5, col = "red", lwd = 3)

HD_dendoClusters <- cutree(tree = HD_dendo, k = 4)
```

After creating the Dendogram, we also want to Performing a k-means Clustering with 4 clusters to see if we will see similar results. Assuming all goes according to intuition, these two methods should result in extremely similar clusters. 
```{r}
set.seed(14)

HD_kmean <-
  HD_std %>%
  kmeans(centers = 4, nstart = 20)

HD_kmeanClusters <- HD_kmean$cluster
```

Let's now compare and see if the two clustering methods matched:   
```{r}
mosaic::tally(HD_dendoClusters ~ HD_kmeanClusters)
```

We can see that both methods had fairly similar clustering. Thus, we go back and check the dendogram to see if the clustering shows any signs of the regions designated by the US Census Bureau. 
```{r}
HD_dendo %>%
  plot(cex = 0.9, labels = HealthData_region$region, lwd = 2,
       main = "Health Data Dendogram with Complete Linkage")
```

Looking at the dendogram by region we can immediately start to see some differntiation, although there certainly are mixes in regions. The left-most cluster is almost entirely Northeast and Southern regions while the cluster farthest to the right is predominately West. In between we can see it almost entirely composed of Midwestern and Southern states, with only a few exceptions in the most rightward cluster. Overall we can see that the different regions do seem to share similarities between themselves, although not extremely distinctly.  

### Unsupervised Learning Summary

Entering the unsupervised learning section we wanted to examine if there are any distinct clusters within the data, especially if it matches with the US Census Bureau regions or not. From our Dendogram and K-means analysis we found that the created clusters do seem to isolate one or two regions, indicating that there likely is some difference between regions, albeit slight at times. From our PCA analysis we found that two principal components accounted for a majority of the variance, approximately represented by intentional drug self-poisoning rates and education levels. Moving forward we can dive deeper into the relationship regions have with state drug mortality rates as well their differing qualities.  



## Conclusions


